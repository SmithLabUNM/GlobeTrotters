group_by(event_id,taxon_id) %>%
summarize(value = sum(value, na.rm = FALSE))
my_data_cleaned <- my_data_benthic %>%
dplyr::select(
event_id, location_id, datetime,
taxon_id, taxon_rank, taxon_name) %>%
distinct() %>%
right_join(my_data_summed)
# check for duplicate records, there should not
# be any at this point.
my_data_cleaned %>%
group_by(event_id, taxon_id) %>%
summarize(n_obs = length(event_id)) %>%
dplyr::filter(n_obs > 1)
# which taxon rank is most common
my_data_cleaned %>%
ggplot(aes(taxon_rank)) +
geom_bar()
# convert densities from per m2 to per cm2
my_data_long <- my_data_cleaned %>%
filter(taxon_rank == "species") %>%
select(event_id, taxon_id, value)
# make data wide
my_data_wide <- my_data_long %>%
pivot_wider(names_from = taxon_id,
values_from = value,
values_fill = list(value = 0)) %>%
tibble::column_to_rownames("event_id")
# Calculate and plot species accumulcation curve for the 11 sampling events
# The CIs are based on random permutations of observed samples
alg_spec_accum_result <- my_data_wide %>% vegan::specaccum(., "random")
plot(alg_spec_accum_result)
# Extract the resampling data used in the above algorithm
spec_resamp_data <- data.frame(
data_set = "observed",
sampling_effort = rep(1:nrow(alg_spec_accum_result$perm),
each = ncol(alg_spec_accum_result$perm)),
richness = c(t(alg_spec_accum_result$perm)))
# Fit species accumulation model
spec_accum_mod_1 <- my_data_wide %>% vegan::fitspecaccum(model = "arrh")
# create a "predicted" data set from the model to extrapolate out
# beyond the number of samples collected
sim_spec_data <- data.frame()
for(i in 1:100){
d_tmp <- data.frame(
data_set = "predicted",
sampling_effort = i,
richness = predict(spec_accum_mod_1, newdata = i))
sim_spec_data <- sim_spec_data %>%
bind_rows(d_tmp)
}
# plot the "observed" and "simulated" curves with 95% CIs
data_plot <- spec_resamp_data %>% bind_rows(sim_spec_data)
data_plot %>%
ggplot(aes(sampling_effort, richness,
color = as.factor(data_set),
fill = as.factor(data_set),
linetype = as.factor(data_set))) +
stat_summary(fun.data = median_hilow, fun.args = list(conf.int = .95),
geom = "ribbon", alpha = 0.25) +
stat_summary(fun.data = median_hilow, geom = "line",
size = 1)
#### LOAD PACKAGES----
require(tidyverse)
require(nlme)
require(dplyr)
require(ggplot2)
require(reshape2)
require(plyr)
require(stringr)
#require(OutlierDetection)
#call maha function from https://cran.r-project.org/src/contrib/Archive/OutlierDetection/
require(utils)
options(stringsAsFactors = FALSE)
base_url_all <-
"https://biscicol.org/futresapi/downloadable/futres.zip"
futres_query_all <- function() {
message("this may take awhile... time for some coffee?")
return(futres_query(base_url_all))
}
# A generic FuTRES query, with queryURL sent as parameter
futres_query <- function(queryUrl) {
message ('sending request for data ...')
message(queryUrl)
# send GET request to the FOVT data portal
results <- httr::GET(queryUrl)
# FOVT data portal returns 204 status code when no results have been found
if (results$status_code == 204) {
message ("no results found!")
return(
list(
"data" = NULL,
"readme" = NULL,
"citation" = NULL,
"number_possible" = 0,
"status_code" = results$status_code
)
)
}
# FOVT server returns a 200 status code when results have been found with
# no server errors
else if (results$status_code == 200) {
bin <- httr::content(results, "raw")
tf <- tempfile()
# save file to disk
writeBin(bin, tf)
# using unzip function compatible with v3 download
unzip(tf, exdir = "futres_download")
# data.csv contains all data as comma separated values
data <- read.csv('futres_download/data.csv', header = TRUE)
# README.txt contains information about the query and the # of results
readme <- readr::read_file('futres_download/FUTRES_README.txt')
# citation_and_data_use_policies.txt contains citation information
citation <- readr::read_file('futres_download/futres_citation_and_data_use_policies.txt')
# grab the number possble from the readme file, using the
# cat function and capturing output so we can grep results
# (server does not return a usable count at this time)
numPossible <- strsplit(grep("total results possible",
capture.output(cat(readme)),
value = TRUE)
,
" = ")
# convert string version with commas to an integer
numPossible <-
as.numeric(gsub(",", "", lapply(numPossible, `[`, 2)))
unlink(tf)
unlink("futres_download/", recursive = TRUE)
return(
list(
"data" = data,
"readme" = readme,
"citation" = citation,
"number_possible" = numPossible,
"status_code" = results$status_code
)
)
}
# Something unexpected happened
else {
message(
paste(
"The server encountered an issue processing your
request and returned status code = ",
results$status_code,
". If the problem persists contact the author."
)
)
return(
list(
"data" = NULL,
"readme" = NULL,
"citation" = NULL,
"number_possible" = NULL,
"status_code" = results$status_code
)
)
}
}
# Accessor function
futres_data <- function(genus = NULL,
specificEpithet = NULL,
termID = NULL,
fromYear = NULL,
toYear = NULL,
country = NULL,
scientificName = NULL,
bbox = NULL,
limit = NULL) {
# Check for minimum arguments to run a query
main_args <- Filter(Negate(is.null),
(as.list(
c(genus, specificEpithet, termID, bbox, country, scientificName)
)))
date_args <-  Filter(Negate(is.null),
(as.list(c(fromYear, toYear))))
arg_lengths <- c(length(main_args), length(date_args))
if (any(arg_lengths) < 1) {
return (futres_query_all())
} else {
# if any query parameters were passed in then call the following
# function which fetches data from elasticsearch
return (
futres_query_partial(
genus,
specificEpithet,
termID,
fromYear,
toYear,
country,
scientificName,
bbox,
limit
)
)
}
}
r_all_futres <- futres_query_all()
futres <- r_all_futres$data
nrow(futres)
nrow(futres[futres$projectID == "Vertnet"])
nrow(futres[futres$projectID == "Vertnet",])
4803002-2428749
4803002/2428749
4818932-4803002
#### LOAD PACKAGES----
require(tidyverse)
require(nlme)
require(dplyr)
require(ggplot2)
require(reshape2)
require(plyr)
require(stringr)
#require(OutlierDetection)
#call maha function from https://cran.r-project.org/src/contrib/Archive/OutlierDetection/
require(utils)
#rfutres package
install.packages("devtools")
install.packages("devtools")
#rfutres package
library(devtools)
devtools::install_github("futres/rfutres")
check()
#rfutres package
library(devtools)
check()
install.packages("devtools")
#rfutres package
library(devtools)
check()
require(devtools)
check()
require(tidyverse)
require(nlme)
require(dplyr)
require(ggplot2)
require(reshape2)
require(plyr)
require(stringr)
#require(OutlierDetection)
#call maha function from https://cran.r-project.org/src/contrib/Archive/OutlierDetection/
require(utils)
options(stringsAsFactors = FALSE)
base_url_all <-
"https://biscicol.org/futresapi/downloadable/futres.zip"
futres_query_all <- function() {
message("this may take awhile... time for some coffee?")
return(futres_query(base_url_all))
}
futres_query <- function(queryUrl) {
message ('sending request for data ...')
message(queryUrl)
# send GET request to the FOVT data portal
results <- httr::GET(queryUrl)
# FOVT data portal returns 204 status code when no results have been found
if (results$status_code == 204) {
message ("no results found!")
return(
list(
"data" = NULL,
"readme" = NULL,
"citation" = NULL,
"number_possible" = 0,
"status_code" = results$status_code
)
)
}
# FOVT server returns a 200 status code when results have been found with
# no server errors
else if (results$status_code == 200) {
bin <- httr::content(results, "raw")
tf <- tempfile()
# save file to disk
writeBin(bin, tf)
# using unzip function compatible with v3 download
unzip(tf, exdir = "futres_download")
# data.csv contains all data as comma separated values
data <- read.csv('futres_download/data.csv', header = TRUE)
# README.txt contains information about the query and the # of results
readme <- readr::read_file('futres_download/FUTRES_README.txt')
# citation_and_data_use_policies.txt contains citation information
citation <- readr::read_file('futres_download/futres_citation_and_data_use_policies.txt')
# grab the number possble from the readme file, using the
# cat function and capturing output so we can grep results
# (server does not return a usable count at this time)
numPossible <- strsplit(grep("total results possible",
capture.output(cat(readme)),
value = TRUE)
,
" = ")
# convert string version with commas to an integer
numPossible <-
as.numeric(gsub(",", "", lapply(numPossible, `[`, 2)))
unlink(tf)
unlink("futres_download/", recursive = TRUE)
return(
list(
"data" = data,
"readme" = readme,
"citation" = citation,
"number_possible" = numPossible,
"status_code" = results$status_code
)
)
}
# Something unexpected happened
else {
message(
paste(
"The server encountered an issue processing your
request and returned status code = ",
results$status_code,
". If the problem persists contact the author."
)
)
return(
list(
"data" = NULL,
"readme" = NULL,
"citation" = NULL,
"number_possible" = NULL,
"status_code" = results$status_code
)
)
}
}
# Accessor function
futres_data <- function(genus = NULL,
specificEpithet = NULL,
termID = NULL,
fromYear = NULL,
toYear = NULL,
country = NULL,
scientificName = NULL,
bbox = NULL,
limit = NULL) {
# Check for minimum arguments to run a query
main_args <- Filter(Negate(is.null),
(as.list(
c(genus, specificEpithet, termID, bbox, country, scientificName)
)))
date_args <-  Filter(Negate(is.null),
(as.list(c(fromYear, toYear))))
arg_lengths <- c(length(main_args), length(date_args))
if (any(arg_lengths) < 1) {
return (futres_query_all())
} else {
# if any query parameters were passed in then call the following
# function which fetches data from elasticsearch
return (
futres_query_partial(
genus,
specificEpithet,
termID,
fromYear,
toYear,
country,
scientificName,
bbox,
limit
)
)
}
}
r_all_futres <- futres_query_all()
str(r_all_futres )
## write out compiled list
write.csv(r_all_futres, "futres_datastore.csv")
## write out data
futres <- r_all_futres$data
nrow(futres)
r_data <- futres_data()
futres_data <- r_data$data
nrow(futres_data)
setwd("~/GitHub/SmithLab/GlobeTrotters/Data")
df <- read.csv('global.mammal.data.csv', header = TRUE)
##load packages----
require(dplyr)
require(purrrlyr)
require(tidyverse)
require(tidyr)
require(reshape2)
require(ggplot2)
require(stringr)
require(ape)
require(caper)
require(phytools)
##DISPERSAL----
df$AFR_d <- as.numeric(df$AFR_d)
df.dispersal <- df %>%
dplyr::group_by(binomial) %>%
dplyr::summarise(n = n(),
foss.avg.age = foss.age*1000000, #in yrs
age = age.median*1000000, #in yrs
avg.mass = avg.mass,
hmrg = home.range.km2,
disp.age = dispersal.age.d,
gen.length = GenerationLength_d,
repro.age = AFR_d,
n.cont = n.cont,
family = family,
order = order,
family.origin = family.origin,
carn = isTRUE(sum(diet.piscivore.tot + diet.invertivore.tot + diet.carnivore.tot) >= 1 & sum(diet.browser.tot + diet.grazer.tot + diet.frugivore.tot) == 0)) %>%
as.data.frame()
df.dispersal <- df.dispersal %>%
drop_na(hmrg, avg.mass)
#calculate dispersal (from Sutherland et al. 2000) (distance in km)
#carnivore: Dc = 40.7M^0.81
#herb or omni = Dho = 3.31M^0.65
df.dispersal$dispersal.distance <- ""
df.dispersal$dispersal.distance[df.dispersal$carn == TRUE] = 40.7*(df.dispersal$avg.mass[df.dispersal$carn == TRUE]^0.81)
df.dispersal$dispersal.distance[df.dispersal$carn != TRUE] = 3.31*(df.dispersal$avg.mass[df.dispersal$carn != TRUE]^0.65)
df.dispersal$dispersal.distance <- as.numeric(df.dispersal$dispersal.distance)
#model: age of dispersal (delay), generation length, age of lineage (fossil age), and dispersal amount
df.dispersal$dispersal.foss =  ((df.dispersal$foss.avg.age * 365)/(df.dispersal$gen.length + df.dispersal$disp.age))*df.dispersal$dispersal.distance
df.dispersal$dispersal.phylo =  ((df.dispersal$age * 365)/(df.dispersal$gen.length + df.dispersal$disp.age))*df.dispersal$dispersal.distance
ggplot(data = df.dispersal) +
geom_density(aes(dispersal.foss))
length(df.dispersal$dispersal.foss[!is.na(df.dispersal$dispersal.foss)]) #68
ggplot(data = df.dispersal) +
geom_density(aes(dispersal.phylo))
length(df.dispersal$dispersal.phylo[!is.na(df.dispersal$dispersal.phylo)]) #84
nrow(df.dispersal[is.na(df.dispersal$dispersal.foss),]) #541
nrow(df.dispersal[is.na(df.dispersal$dispersal.phylo),]) #526
length(unique(df.dispersal$family[is.na(df.dispersal$dispersal.foss)])) #85
length(unique(df.dispersal$family[is.na(df.dispersal$dispersal.phylo)])) #83
table(df.dispersal$order[is.na(df.dispersal$dispersal.foss)])
table(df.dispersal$order[is.na(df.dispersal$dispersal.phylo)])
nrow(df.dispersal[!is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Rodentia",]) #12
nrow(df.dispersal[!is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Primates",]) #0
table(df.dispersal$family.origin[is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Primates"])
table(df.dispersal$family.origin[is.na(df.dispersal$dispersal.phylo) &
df.dispersal$order == "Primates"])
ks.test(df.dispersal$avg.mass[!is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Rodentia"],
df.dispersal$avg.mass[is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Rodentia"])
ks.test(df.dispersal$avg.mass[!is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Rodentia"],
df.dispersal$avg.mass[is.na(df.dispersal$dispersal.foss) &
df.dispersal$order == "Rodentia"],
alternative = "less") #y lies below x;
#round up
Eurasia.EW = 9907
Eurasia.NS = 7969
Africa.EW = 7326
Africa.NS = 8023
North.America.EW = 5949
North.America.NS = 7612
South.America.EW = 5055
South.America.NS = 7429
Australia.EW = 3624
Australia.NS = 2993
length(df.dispersal$binomial[!is.na(df.dispersal$dispersal.foss)]) #68
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Australia.EW & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Australia.NS & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Eurasia.EW & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Eurasia.NS & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Africa.EW & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= Africa.NS & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= North.America.EW & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= North.America.NS & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= South.America.EW & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[df.dispersal$dispersal.foss >= South.America.NS & !is.na(df.dispersal$dispersal.foss)])
length(df.dispersal$binomial[!is.na(df.dispersal$dispersal.phylo)]) #84
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Australia.EW & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Australia.NS & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Eurasia.EW & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Eurasia.NS & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Africa.EW & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= Africa.NS & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= North.America.EW & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= North.America.NS & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= South.America.EW & !is.na(df.dispersal$dispersal.phylo)])
length(df.dispersal$binomial[df.dispersal$dispersal.phylo >= South.America.NS & !is.na(df.dispersal$dispersal.phylo)])
homies <- df[df$n.cont == 1,]
limited <- df[df$n.cont == 2,]
trotter <- df[df$n.cont == "3+",]
#homies
homies.origin <- homies %>%
group_by(family.origin) %>%
dplyr::summarise(N = n(),
N.Africa = length(continent.Africa[continent.Africa == TRUE]),
N.Australia = length(continent.Australia[continent.Australia == TRUE]),
N.South.America = length(continent.South.America[continent.South.America == TRUE]),
N.North.America = length(continent.North.America[continent.North.America == TRUE]),
N.Eurasia = length(continent.Eurasia[continent.Eurasia == TRUE])) %>%
as.data.frame()
homies.origin <- homies.origin[homies.origin$family.origin != "",]
#get proportions
homies.origin$N.jump <- ""
homies.origin$prop.origin <- ""
homies.origin$prop.jump <- ""
homies.origin$N.jump[homies.origin$family.origin == "Africa"] <- as.numeric(homies.origin$N[homies.origin$family.origin == "Africa"] - homies.origin$N.Africa[homies.origin$family.origin == "Africa"])
homies.origin$prop.origin[homies.origin$family.origin == "Africa"] <- as.numeric(homies.origin$N.Africa[homies.origin$family.origin == "Africa"]/homies.origin$N[homies.origin$family.origin == "Africa"])
homies.origin$prop.jump[homies.origin$family.origin == "Africa"] <- as.numeric(homies.origin$N.jump[homies.origin$family.origin == "Africa"])/as.numeric(homies.origin$N[homies.origin$family.origin == "Africa"])
homies.origin$N.jump[homies.origin$family.origin == "Australia"] <- as.numeric(homies.origin$N[homies.origin$family.origin == "Australia"] - homies.origin$N.Australia[homies.origin$family.origin == "Australia"])
homies.origin$prop.origin[homies.origin$family.origin == "Australia"] <- as.numeric(homies.origin$N.Australia[homies.origin$family.origin == "Australia"]/homies.origin$N[homies.origin$family.origin == "Australia"])
homies.origin$prop.jump[homies.origin$family.origin == "Australia"] <- as.numeric(homies.origin$N.jump[homies.origin$family.origin == "Australia"])/as.numeric(homies.origin$N[homies.origin$family.origin == "Australia"])
homies.origin$N.jump[homies.origin$family.origin == "North.America"] <- as.numeric(homies.origin$N[homies.origin$family.origin == "North.America"] - homies.origin$N.North.America[homies.origin$family.origin == "North.America"])
homies.origin$prop.origin[homies.origin$family.origin == "North.America"] <- as.numeric(homies.origin$N.North.America[homies.origin$family.origin == "North.America"]/homies.origin$N[homies.origin$family.origin == "North.America"])
homies.origin$prop.jump[homies.origin$family.origin == "North.America"] <- as.numeric(homies.origin$N.jump[homies.origin$family.origin == "North.America"])/as.numeric(homies.origin$N[homies.origin$family.origin == "North.America"])
homies.origin$N.jump[homies.origin$family.origin == "South.America"] <- as.numeric(homies.origin$N[homies.origin$family.origin == "South.America"] - homies.origin$N.South.America[homies.origin$family.origin == "South.America"])
homies.origin$prop.origin[homies.origin$family.origin == "South.America"] <- as.numeric(homies.origin$N.South.America[homies.origin$family.origin == "South.America"]/homies.origin$N[homies.origin$family.origin == "South.America"])
homies.origin$prop.jump[homies.origin$family.origin == "South.America"] <- as.numeric(homies.origin$N.jump[homies.origin$family.origin == "South.America"])/as.numeric(homies.origin$N[homies.origin$family.origin == "South.America"])
homies.origin$N.jump[homies.origin$family.origin == "Eurasia"] <- as.numeric(homies.origin$N[homies.origin$family.origin == "Eurasia"] - homies.origin$N.Eurasia[homies.origin$family.origin == "Eurasia"])
homies.origin$prop.origin[homies.origin$family.origin == "Eurasia"] <- as.numeric(homies.origin$N.Eurasia[homies.origin$family.origin == "Eurasia"]/homies.origin$N[homies.origin$family.origin == "Eurasia"])
homies.origin$prop.jump[homies.origin$family.origin == "Eurasia"] <- as.numeric(homies.origin$N.jump[homies.origin$family.origin == "Eurasia"])/as.numeric(homies.origin$N[homies.origin$family.origin == "Eurasia"])
homies.origin
